# -*- coding: utf-8 -*-
"""Retina_mnist_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qP5Hd9RxRdoqm8sv9wFm0AtvDVq2BLIW
"""

# import package
import matplotlib.pyplot as plt
import numpy as np
import os

import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import (Input, Dense, Dropout, Activation, GlobalAveragePooling2D,
                    BatchNormalization, Flatten, Conv2D, MaxPooling2D)

#需安裝google download套件, Google Drive direct download of big files.
#pip install gdown

tf.__version__

#確認CPU&GPU裝置狀況
from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

"""### MedMNIST
MedMNIST, a collection of 10 pre-processed medical open datasets. MedMNIST is standardized to perform classification tasks on lightweight 28 * 28 images, which requires no background knowledge. Covering the primary data modalities in medical image analysis, it is diverse on data scale (from 100 to 100,000) and tasks (binary/multi-class, ordinal regression and multi-label). MedMNIST could be used for educational purpose, rapid prototyping, multi-modal machine learning or AutoML in medical image analysis. Moreover, MedMNIST Classification Decathlon is designed to benchmark AutoML algorithms on all 10 datasets.
(著者: 上海交通大學 Jiancheng Yang, Rui Shi, Bingbing Ni, Bilian Ke)

[GitHub Pages 連結](https://github.com/MedMNIST/MedMNIST)

<img src="https://medmnist.github.io/assets/overview.jpg" alt="MedMNIST figure" width="700">

PneumoniaMNIST資料集下載(google drive): https://drive.google.com/file/d/1nebGwtoKTNegJ-fUYO-NEz0mzC1481hv/view?usp=sharing

## PneumoniaMNIST:
**PneumoniaMNIST:** 
A dataset based on a prior dataset of 5,856 pediatric chest X-ray images. The task is binary-class classification of pneumonia and normal. We split the source training set with a ratio of 9:1 into training and validation set, and use its source validation set as the test set. The source images are single-channel, and their sizes range from (384-2,916) x (127-2,713). We center-crop the images and resize them into 1 x 28 x 28.

**task:** Binary-Class (2)

**label:**

      0: normal, 1: pneumonia

**n_channels:** 1

**n_samples:** 

     train: 4708, val: 524, test: 624


"""

# find the share link of the file/folder on Google Drive
file_share_link = "https://drive.google.com/file/d/1Fg7XUhOAZk0qdNEyAnbJ_mGZnNmVTSBD/view?usp=sharing"

# extract the ID of the file
file_id = "1Fg7XUhOAZk0qdNEyAnbJ_mGZnNmVTSBD"
# download file name
file_name = 'retinamnist.npz'

!gdown --id "$file_id" --output "$file_name"

!ls -lh

"""# 資料探索"""

import numpy as np
#load pneumoniamnist dataset
retinamnist = np.load('retinamnist.npz')

type(retinamnist) #include files: train_images, val_images, test_images, train_labels, val_labels, test_labels

retinamnist['train_images'].shape, retinamnist['train_labels'].shape

(x_train, y_train), (x_test, y_test) = (retinamnist['train_images'], retinamnist['train_labels']), (retinamnist['test_images'], retinamnist['test_labels'])
(x_val, y_val) = (retinamnist['val_images'], retinamnist['val_labels'])

print(x_train.shape)  # (4708, 28, 28)
print(y_train.shape)  # (4708, 1)
print(y_train[40:50])  # class-label

print(x_test.shape)  # (624, 28, 28)
print(y_test.shape)  # (624, 1)

# 將資料集轉成 'float32'
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

# rescale value to [0 - 1] from [0 - 255]
x_train /= 255  # rescaling
x_test /= 255   # rescaling

x_val = x_val.astype('float32')/255

def rgb2gray(rgb):
        return np.dot(rgb[..., :3], [0.299, 0.587, 0.114])
              
new = [] 
for i in range(len(x_train)):
  a = rgb2gray(x_train[i])
  new.append(a)
x_train  = new

new = [] 
for i in range(len(x_test)):
  a = rgb2gray(x_test[i])
  new.append(a)
x_test  = new

new = [] 
for i in range(len(x_val)):
  a = rgb2gray(x_val[i])
  new.append(a)
x_val  = new

# montage
# source: https://github.com/MedMNIST/MedMNIST/blob/main/getting_started.ipynb
from skimage.util import montage
# plt.imshow(x_train[0])

                      
def process(dataset, n_channels, length=20):
    scale = length * length
    image = np.zeros((scale, 28, 28, 3)) if n_channels == 3 else np.zeros((scale, 28, 28))
    index = [i for i in range(scale)]
    np.random.shuffle(index)
    plt.figure(figsize=(6,6))

    for idx in range(scale):
        # print(idx)
        img = dataset[idx]
        # print(img.shape)
        if n_channels == 3:
            img = img.permute(1, 2, 0)
        else:
            img = img.reshape(28, 28)
        image[index[idx]] = img

    if n_channels == 1:
        image = image.reshape(scale, 28, 28)
        arr_out = montage(image)
        plt.imshow(arr_out, cmap='gray')
    else:
        image = image.reshape(scale, 28, 28, 3)
        arr_out = montage(image, multichannel=3)
        plt.imshow(arr_out)
    
process( x_train, n_channels=1, length=5)

# visualization
import matplotlib.pylab as plt
sample_num = 99
img = x_train[sample_num].reshape(28, 28)
plt.imshow(img, cmap='gray')
template = "label:{label}"
_ = plt.title(template.format(label= str(y_train[sample_num])))
plt.grid(False)

"""# 搭建資料流"""

x_train = np.array(x_train)
x_train.shape+(1,)

np.expand_dims(x_train, axis=3).shape

x_train = np.expand_dims(x_train, axis=3)
print('x_train shape:',x_train.shape)
x_test = np.expand_dims(x_test, axis=3)
print('x_test shape:',x_test.shape)
x_val = np.expand_dims(x_val, axis=3)
print('x_val shape:',x_val.shape)

# 將訓練資料與測試資料的 label，進行 Onehot encoding 轉換
num_classes = 5

from tensorflow.keras.utils import to_categorical
y_train_onehot = to_categorical(y_train)
y_test_onehot = to_categorical(y_test)
y_val_onehot = to_categorical(y_val)

print('y_train_onehot shape:', y_train_onehot.shape)
print('y_test_onehot shape:', y_test_onehot.shape)
print('y_val_onehot shape:', y_val_onehot.shape)

input = Input(shape=x_train.shape[1:])

x = Conv2D(32, (3, 3), activation='relu', padding='same')(input)
x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
x = MaxPooling2D(pool_size=(2, 2))(x)

x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
x = Conv2D(64, (3, 3), activation='relu', padding='same', name='last_conv_layer')(x)

x = GlobalAveragePooling2D(name='avg_pool')(x)
output = Dense(num_classes, activation='softmax', name='predictions')(x)

model = Model(inputs=[input], outputs=[output])

print(model.summary())

tf.keras.utils.plot_model(
 model,
 to_file='model_plot_CNN.png',
 show_shapes=True,
 show_layer_names=True,
 rankdir='TB',
 expand_nested=True,
 dpi=96,
)

"""# 模型訓練"""

# 編譯模型
# 選用 Adam 為 optimizer
from keras.optimizers import Adam

batch_size = 256
epochs = 20
init_lr = 0.001
opt = Adam(lr=init_lr)

model.compile(optimizer = opt, loss='categorical_crossentropy', metrics='accuracy')

cnn_history = model.fit(x_train, y_train_onehot,
                  batch_size=batch_size,
                  epochs=epochs,
                  validation_data=(x_val, y_val_onehot),
                  verbose=2)

import plotly.graph_objects as go
plt.clf()
fig = go.Figure()
fig.add_trace(go.Scatter( y=cnn_history.history['accuracy'],
              name='Train'))
fig.add_trace(go.Scatter( y=cnn_history.history['val_accuracy'],
              name='Valid'))
fig.update_layout(height=500,width=700,
              title='Accuracy for race feature',
              xaxis_title='Epoch',
              yaxis_title='Accuracy')
fig.show()

predictions = model.predict(x_test)
print(predictions.shape)
print(predictions[0:5])
print("**********************************************")
plt.hist(predictions)
plt.show()

y_pred = np.argmax(predictions, axis=1)
print(y_pred.shape)
print(y_pred[0:5])
print("**********************************************")
plt.hist(y_pred)
plt.show()

"""# 模型評估"""

cnn_pred = model.evaluate(x_test, y_test_onehot, verbose=2)



y_pred[0:10], y_pred.shape

_y_test = y_test.reshape(y_pred.shape)
_y_test[0:10], _y_test.shape

# visualization
import matplotlib.pylab as plt
sample_num = 1
img = x_test[sample_num].reshape(28, 28)
plt.imshow(img, cmap='gray')
template = "True:{true}, predicted:{predict}"
_ = plt.title(template.format(true= str(y_test[sample_num]),
                predict= str(y_pred[sample_num])))
plt.grid(False)

"""# 解釋模型

**tf-keras-vis**
tf-keras-vis is a visualization toolkit for debugging tf.keras models in Tensorflow2.0+.
[github 連結](https://github.com/keisen/tf-keras-vis)

**grad-CAM**

<img src="https://github.com/keisen/tf-keras-vis/raw/master/examples/images/gradcam_plus_plus.png" alt="gradcam figure" width="700">
"""

#需安裝一下套件
!pip install tf-keras-vis

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from matplotlib import cm
# import matplotlib.pyplot as plt
# from tf_keras_vis.gradcam import Gradcam,GradcamPlusPlus
# from tensorflow.keras import backend as K
# from tf_keras_vis.saliency import Saliency
# from tf_keras_vis.utils import normalize
# 
# def Grad_CAM_savepictures(file_index,model,save_name):
#   def loss(output):
#     return (output[0][y_test[file_index][0]])
#   def model_modifier(m):
#     m.layers[-1].activation = tf.keras.activations.linear
#     return m
#   # Create Gradcam object
#   gradcam = Gradcam(model,model_modifier=model_modifier,clone=False)
#   originalimage=x_test[file_index]
#   originalimage=originalimage.reshape((1,originalimage.shape[0],originalimage.shape[1],1))
# 
#   # Generate heatmap with GradCAM
#   cam = gradcam(loss,originalimage,penultimate_layer=-1)
#   cam = normalize(cam)
# 
#   #overlap image
#   plt.figure(figsize=(12,8))
#   ax1=plt.subplot(1, 3, 1)
#   heatmap = np.uint8(cm.jet(cam)[..., :3] * 255)
#   ax1.imshow(x_test[file_index].reshape((x_test.shape[1],x_test.shape[2])),cmap="gray")
#   ax1.imshow(heatmap.reshape((x_test.shape[1],x_test.shape[2],3)), cmap='jet', alpha=0.4) # overlay
#   ax1.set_title("Grad-CAM")
# 
#   gradcam = GradcamPlusPlus(model,model_modifier=model_modifier,clone=False)
#   cam = gradcam(loss,originalimage,penultimate_layer=-1)
#   cam = normalize(cam)
# 
#   ax1=plt.subplot(1, 3, 2)
#   heatmap = np.uint8(cm.jet(cam)[..., :3] * 255)
#   ax1.imshow(x_test[file_index].reshape((x_test.shape[1],x_test.shape[2])),cmap="gray")
#   ax1.imshow(heatmap.reshape((x_test.shape[1],x_test.shape[2],3)), cmap='jet', alpha=0.4) # overlay
#   ax1.set_title("Grad-CAM++")
# 
#   plt.savefig(save_name)
#   plt.show()

file_index = 0
Grad_CAM_savepictures( file_index, model, "Grad-CAM_{}.jpg".format(file_index))
print('saved file - Grad-CAM_{}.jpg'.format(file_index))

file_index = 1
Grad_CAM_savepictures( file_index, model, "Grad-CAM_{}.jpg".format(file_index))
print('saved file - Grad-CAM_{}.jpg'.format(file_index))

file_index = 2
Grad_CAM_savepictures( file_index, model, "Grad-CAM_{}.jpg".format(file_index))
print('saved file - Grad-CAM_{}.jpg'.format(file_index))

file_index = 10
Grad_CAM_savepictures( file_index, model, "Grad-CAM_{}.jpg".format(file_index))
print('saved file - Grad-CAM_{}.jpg'.format(file_index))

